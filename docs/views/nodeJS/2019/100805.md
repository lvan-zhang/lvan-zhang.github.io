---
title: node爬虫：爬取csdn的文章源文件
date: 2019-10-08
tags:
  - nodeJS
categories:
  - nodeJS
---

:::tip
需求
最近自己搞了个博客 https://lvan-zhang.github.io ，于是准备把 csdn 上的文章扒拉过来，手动简单的试了一下：

点开每一个文章的编辑按钮
复制文章的源文字（markdown），复制到自己博客的 markdown 文件中。
并在新的文件开头按照格式注上标题、日期等等

这些操作全部手动来做的话那是要累死个羊的，于是准备写点代码实现自动化，虽说 python 用来...
:::

<!-- more -->

## 需求
最近自己搞了个博客 [https://lvan-zhang.github.io](https://lvan-zhang.github.io) ，于是准备把 csdn 上的文章扒拉过来，手动简单的试了一下：
- 点开每一个文章的编辑按钮
- 复制文章的源文字（markdown），复制到自己博客的 markdown 文件中。
- 并在新的文件开头按照格式注上标题、日期等等

这些操作全部手动来做的话那是要累死个羊的，于是准备写点代码实现自动化，虽说 python 用来做爬虫比较方便，奈何对这门语言不是很熟悉，于是挑选我们的本命语言 javascript 来整 ！
## 库的选择
1. express
不多哔哔，node 最常用的框架，简化 http 请求，如果你比较潮的话也可以用 Koa
2. cheerio
可以像 jquery 一样操作，用来分析网页内容，爬虫不用这个库你拿命爬？
3. superagent
模拟打开一个网页，获取页面信息。
superagent-charset 是这个模块的拓展，因为 superagent 只支持 UTF-8，用了这个库可以指定编码，当你用 superagent 爬出乱码时可以使用它。
>如果不想用库，那就是原生的 http 模块，需要解析文件流之类的，略微麻烦。其他关于 http 请求的库还有 request、axios（服务端）、got（轻量）
4. chalk
美化打印文字，可有可无
5. log4js
日志模块，其他的还有 debug 模块
6. sequelize 或 mongoose
数据库用 mysql 和 sqllite 之类的建议用 sequelize，如果是 mongodb，推荐 mongoose
7. puppeteer
无头浏览器。我们可以用来抓取一些通过 js 渲染而不是直接存在于页面源代码中的信息。比如 spa 页面，页面内容都是 js 渲染出来的。我们可以调用 puppeteer 在页面某个标签出现时获取到页面当时的渲染出来的 html。
8. async + eventproxy
控制并发请求
9. node-xlsx
fs 模块并不能直接写入 xlsx，所以用这个。

注：以上的库并不是全部用到了，可以给大家具体需求的一个参考~
## 开始
```shell
cd ~/web/node-all
mkdir crawl-csdn-blog
cd crawl-csdn-blog
npm init -y
touch index.js
npm install express cheerio --save
```
创建完后，打开 index.js 就是干
```js
未完待续...
```
