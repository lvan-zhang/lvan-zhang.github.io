(window.webpackJsonp=window.webpackJsonp||[]).push([[79],{440:function(s,t,n){"use strict";n.r(t);var a=n(0),e=Object(a.a)({},(function(){var s=this,t=s.$createElement,n=s._self._c||t;return n("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[n("div",{staticClass:"custom-block tip"},[n("p",[s._v("需求\n最近自己搞了个博客 https://lvan-zhang.github.io ，于是准备把 csdn 上的文章扒拉过来，手动简单的试了一下：")]),s._v(" "),n("p",[s._v("点开每一个文章的编辑按钮\n复制文章的源文字（markdown），复制到自己博客的 markdown 文件中。\n并在新的文件开头按照格式注上标题、日期等等")]),s._v(" "),n("p",[s._v("这些操作全部手动来做的话那是要累死个羊的，于是准备写点代码实现自动化，虽说 python 用来...")])]),s._v(" "),n("h2",{attrs:{id:"需求"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#需求"}},[s._v("#")]),s._v(" 需求")]),s._v(" "),n("p",[s._v("最近自己搞了个博客 "),n("a",{attrs:{href:"https://lvan-zhang.github.io",target:"_blank",rel:"noopener noreferrer"}},[s._v("https://lvan-zhang.github.io"),n("OutboundLink")],1),s._v(" ，于是准备把 csdn 上的文章扒拉过来，手动简单的试了一下：")]),s._v(" "),n("ul",[n("li",[s._v("点开每一个文章的编辑按钮")]),s._v(" "),n("li",[s._v("复制文章的源文字（markdown），复制到自己博客的 markdown 文件中。")]),s._v(" "),n("li",[s._v("并在新的文件开头按照格式注上标题、日期等等")])]),s._v(" "),n("p",[s._v("这些操作全部手动来做的话那是要累死个羊的，于是准备写点代码实现自动化，虽说 python 用来做爬虫比较方便，奈何对这门语言不是很熟悉，于是挑选我们的本命语言 javascript 来整 ！")]),s._v(" "),n("h2",{attrs:{id:"库的选择"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#库的选择"}},[s._v("#")]),s._v(" 库的选择")]),s._v(" "),n("ol",[n("li",[s._v("express\n不多哔哔，node 最常用的框架，简化 http 请求，如果你比较潮的话也可以用 Koa")]),s._v(" "),n("li",[s._v("cheerio\n可以像 jquery 一样操作，用来分析网页内容，爬虫不用这个库你拿命爬？")]),s._v(" "),n("li",[s._v("superagent\n模拟打开一个网页，获取页面信息。\nsuperagent-charset 是这个模块的拓展，因为 superagent 只支持 UTF-8，用了这个库可以指定编码，当你用 superagent 爬出乱码时可以使用它。")])]),s._v(" "),n("blockquote",[n("p",[s._v("如果不想用库，那就是原生的 http 模块，需要解析文件流之类的，略微麻烦。其他关于 http 请求的库还有 request、axios（服务端）、got（轻量）")])]),s._v(" "),n("ol",{attrs:{start:"4"}},[n("li",[s._v("chalk\n美化打印文字，可有可无")]),s._v(" "),n("li",[s._v("log4js\n日志模块，其他的还有 debug 模块")]),s._v(" "),n("li",[s._v("sequelize 或 mongoose\n数据库用 mysql 和 sqllite 之类的建议用 sequelize，如果是 mongodb，推荐 mongoose")]),s._v(" "),n("li",[s._v("puppeteer\n无头浏览器。我们可以用来抓取一些通过 js 渲染而不是直接存在于页面源代码中的信息。比如 spa 页面，页面内容都是 js 渲染出来的。我们可以调用 puppeteer 在页面某个标签出现时获取到页面当时的渲染出来的 html。")]),s._v(" "),n("li",[s._v("async + eventproxy\n控制并发请求")]),s._v(" "),n("li",[s._v("node-xlsx\nfs 模块并不能直接写入 xlsx，所以用这个。")])]),s._v(" "),n("p",[s._v("注：以上的库并不是全部用到了，可以给大家具体需求的一个参考~")]),s._v(" "),n("h2",{attrs:{id:"开始"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#开始"}},[s._v("#")]),s._v(" 开始")]),s._v(" "),n("div",{staticClass:"language-shell line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("cd")]),s._v(" ~/web/node-all\n"),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("mkdir")]),s._v(" crawl-csdn-blog\n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("cd")]),s._v(" crawl-csdn-blog\n"),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("npm")]),s._v(" init -y\n"),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("touch")]),s._v(" index.js\n"),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("npm")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("install")]),s._v(" express cheerio --save\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br")])]),n("p",[s._v("创建完后，打开 index.js 就是干")]),s._v(" "),n("div",{staticClass:"language-js line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[s._v("未完待续"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("...")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br")])])])}),[],!1,null,null,null);t.default=e.exports}}]);